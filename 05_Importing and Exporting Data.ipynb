{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f22565c",
   "metadata": {},
   "source": [
    "<div style=\"color:#006666; padding:0px 10px; border-radius:5px; font-size:18px; text-align:center\"><h1 style='margin:10px 5px'>Import and Export Data</h1>\n",
    "<hr>\n",
    "<p style=\"color:#006666; text-align:right;font-size:10px\">\n",
    "Copyright by MachineLearningPlus. All Rights Reserved.\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d865a",
   "metadata": {},
   "source": [
    "We don't usually create the arrays that we work with. You need to be able to bring data present in another file to Numpy.\n",
    "\n",
    "Numpy provides useful functions to load data from an external file and save it as well.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:7px 5px; font-size:16px'>Import Data</h2>\n",
    "</div>\n",
    "\n",
    "The main import methods are:\n",
    "\n",
    "1. numpy.loadtxt()\n",
    "2. numpy.genfromtext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab060ab",
   "metadata": {},
   "source": [
    "Use `np.loadtxt` when there is no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f862cf01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     , 87.     , 57.54435],\n",
       "       [ 2.     ,  8.     ,  7.31704],\n",
       "       [ 3.     , 56.     , 56.82095],\n",
       "       [ 4.     , 63.     , 64.15579],\n",
       "       [ 5.     ,  2.     ,  5.74522],\n",
       "       [ 6.     , 45.     , 19.56758],\n",
       "       [ 7.     , 43.     , 39.62271],\n",
       "       [ 8.     , 47.     , 34.95107],\n",
       "       [ 9.     ,  2.     ,  9.38692],\n",
       "       [10.     , 79.     , 36.41022],\n",
       "       [11.     , 67.     , 49.83894],\n",
       "       [12.     , 24.     , 23.47974],\n",
       "       [13.     , 61.     , 72.55357],\n",
       "       [14.     , 85.     , 39.24693],\n",
       "       [15.     , 63.     , 53.6279 ],\n",
       "       [16.     ,  2.     , 16.72441],\n",
       "       [17.     , 29.     , 37.25533],\n",
       "       [18.     , 45.     , 18.78498],\n",
       "       [19.     , 33.     , 19.8089 ],\n",
       "       [20.     , 28.     , 46.03384],\n",
       "       [21.     , 21.     , 23.7864 ],\n",
       "       [22.     , 27.     , 44.42627],\n",
       "       [23.     , 65.     , 34.94804],\n",
       "       [24.     , 61.     , 53.49576],\n",
       "       [25.     , 10.     , 25.98564]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('Datasets/data.txt', delimiter=\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1068d311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.     , 87.     , 57.54435])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29894586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3054d0",
   "metadata": {},
   "source": [
    "When there are missing values, it errors out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13e3f87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4f162b15d9ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Datasets/data_miss.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ndh00130\\appdata\\local\\continuum\\anaconda3\\envs\\timeseries\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ndh00130\\appdata\\local\\continuum\\anaconda3\\envs\\timeseries\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ndh00130\\appdata\\local\\continuum\\anaconda3\\envs\\timeseries\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ndh00130\\appdata\\local\\continuum\\anaconda3\\envs\\timeseries\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('Datasets/data_miss.txt', delimiter=\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569634d",
   "metadata": {},
   "source": [
    "In such situation, use `np.genfromtxt()`. It fills in missing data with `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b88b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     , 87.     , 57.54435],\n",
       "       [ 2.     ,  8.     ,  7.31704],\n",
       "       [ 3.     , 56.     , 56.82095],\n",
       "       [ 4.     , 63.     , 64.15579],\n",
       "       [ 5.     ,  2.     ,  5.74522],\n",
       "       [ 6.     , 45.     , 19.56758],\n",
       "       [ 7.     , 43.     , 39.62271],\n",
       "       [ 8.     , 47.     , 34.95107],\n",
       "       [ 9.     ,  2.     ,      nan],\n",
       "       [10.     , 79.     , 36.41022],\n",
       "       [11.     , 67.     , 49.83894],\n",
       "       [12.     , 24.     ,      inf],\n",
       "       [13.     , 61.     , 72.55357],\n",
       "       [14.     , 85.     , 39.24693],\n",
       "       [15.     , 63.     , 53.6279 ],\n",
       "       [16.     ,  2.     , 16.72441],\n",
       "       [17.     , 29.     ,      nan],\n",
       "       [18.     , 45.     , 18.78498],\n",
       "       [19.     , 33.     , 19.8089 ],\n",
       "       [20.     , 28.     , 46.03384],\n",
       "       [21.     , 21.     , 23.7864 ],\n",
       "       [22.     , 27.     , 44.42627],\n",
       "       [23.     , 65.     , 34.94804],\n",
       "       [24.     , 61.     , 53.49576],\n",
       "       [25.     , 10.     , 25.98564]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('Datasets/data_miss.txt', delimiter=\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d6d4c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:7px 5px; font-size:16px'>CSV File</h2>\n",
    "</div>\n",
    "\n",
    "Let's try loading a csv file with column names.\n",
    "\n",
    "By default, it takes the dtype as `float`. In such cases, the text fields will go missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b3865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan,  nan,  nan],\n",
       "       [  1.,  nan,  19.,  15.,  39.],\n",
       "       [  2.,  nan,  21.,  15.,  81.],\n",
       "       ...,\n",
       "       [198.,  nan,  32., 126.,  74.],\n",
       "       [199.,  nan,  32., 137.,  18.],\n",
       "       [200.,  nan,  30., 137.,  83.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('Datasets/Mall_Customers.csv', delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc92eb4",
   "metadata": {},
   "source": [
    "So, explicitly mention the datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcb130d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'1', b'Male', b'19', b'15', b'39'],\n",
       "       [b'2', b'Male', b'21', b'15', b'81'],\n",
       "       [b'3', b'Female', b'20', b'16', b'6'],\n",
       "       [b'4', b'Female', b'23', b'16', b'77'],\n",
       "       [b'5', b'Female', b'31', b'17', b'40']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change dtype and skip header\n",
    "data = np.genfromtxt('Datasets/Mall_Customers.csv', \n",
    "                     delimiter=\",\", \n",
    "                     dtype='object',\n",
    "                    skip_header=1)\n",
    "\n",
    "data[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c587d0",
   "metadata": {},
   "source": [
    "The problem with this is, the numbers are identified as bytes and not as numbers. So doing math is not easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327685fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'bytes' and 'bytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cd82040a9128>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Divide 3rd col by 2nd col. ERROR!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'bytes' and 'bytes'"
     ]
    }
   ],
   "source": [
    "# Divide 3rd col by 2nd col. ERROR!\n",
    "data[:, 3] / data[:, 2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27087f2f",
   "metadata": {},
   "source": [
    "Convert to float and then divide. Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757135b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78947368, 0.71428571, 0.8       , 0.69565217, 0.5483871 ,\n",
       "       0.77272727, 0.51428571, 0.7826087 , 0.296875  , 0.63333333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = data[:, 3].astype('float') / data[:, 2].astype('float')\n",
    "output[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5add8a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:7px 5px; font-size:16px'>Better Way: Define the Data Type and then import</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c5e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.dtype({'names': [\"CustomerID\", \"Genre\", \"Age\", \"Annual_Income\", \"Spending_Score\"],\n",
    "               'formats': [np.int16, 'U16', np.int16, np.int16, np.int16]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c961807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 1, 'Male', 19, 15, 39), ( 2, 'Male', 21, 15, 81),\n",
       "       ( 3, 'Female', 20, 16,  6), ( 4, 'Female', 23, 16, 77),\n",
       "       ( 5, 'Female', 31, 17, 40), ( 6, 'Female', 22, 17, 76),\n",
       "       ( 7, 'Female', 35, 18,  6), ( 8, 'Female', 23, 18, 94),\n",
       "       ( 9, 'Male', 64, 19,  3), (10, 'Female', 30, 19, 72),\n",
       "       (11, 'Male', 67, 19, 14), (12, 'Female', 35, 19, 99),\n",
       "       (13, 'Female', 58, 20, 15), (14, 'Female', 24, 20, 77),\n",
       "       (15, 'Male', 37, 20, 13)],\n",
       "      dtype=[('CustomerID', '<i2'), ('Genre', '<U16'), ('Age', '<i2'), ('Annual_Income', '<i2'), ('Spending_Score', '<i2')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change dtype and skip header\n",
    "data = np.genfromtxt('Datasets/Mall_Customers.csv', \n",
    "                     delimiter=\",\", \n",
    "                     dtype=dt,\n",
    "                    skip_header=1)\n",
    "\n",
    "data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1432daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6a28fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4cd2a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Male'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93106cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 21, 20, 23, 31, 22, 35, 23, 64, 30, 67, 35, 58, 24, 37, 22, 35,\n",
       "       20, 52, 35, 35, 25, 46, 31, 54, 29, 45, 35, 40, 23, 60, 21, 53, 18,\n",
       "       49, 21, 42, 30, 36, 20, 65, 24, 48, 31, 49, 24, 50, 27, 29, 31, 49,\n",
       "       33, 31, 59, 50, 47, 51, 69, 27, 53, 70, 19, 67, 54, 63, 18, 43, 68,\n",
       "       19, 32, 70, 47, 60, 60, 59, 26, 45, 40, 23, 49, 57, 38, 67, 46, 21,\n",
       "       48, 55, 22, 34, 50, 68, 18, 48, 40, 32, 24, 47, 27, 48, 20, 23, 49,\n",
       "       67, 26, 49, 21, 66, 54, 68, 66, 65, 19, 38, 19, 18, 19, 63, 49, 51,\n",
       "       50, 27, 38, 40, 39, 23, 31, 43, 40, 59, 38, 47, 39, 25, 31, 20, 29,\n",
       "       44, 32, 19, 35, 57, 32, 28, 32, 25, 28, 48, 32, 34, 34, 43, 39, 44,\n",
       "       38, 47, 27, 37, 30, 34, 30, 56, 29, 19, 31, 50, 36, 42, 33, 36, 32,\n",
       "       40, 28, 36, 36, 52, 30, 58, 27, 59, 35, 37, 32, 46, 29, 41, 30, 54,\n",
       "       28, 41, 36, 34, 32, 33, 38, 47, 35, 45, 32, 32, 30], dtype=int16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd2856",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:7px 5px; font-size:16px'>Export Data and Load it back</h2>\n",
    "</div>\n",
    "\n",
    "If it's a single array, save it in `.npy` format. If you have multiple arrays to save in same file, use `.npz` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a937db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the arrays to disk\n",
    "\n",
    "# Single array\n",
    "np.save('TEMP/output.npy', output)\n",
    "\n",
    "# Multiple arrays: arrays will be save with names \"arr_0\", \"arr_1\",..\n",
    "np.savez('TEMP/outputs.npz', output, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908cd6c",
   "metadata": {},
   "source": [
    "Load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f12cdf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78947368, 0.71428571, 0.8       , 0.69565217, 0.5483871 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single array\n",
    "a = np.load('TEMP/output.npy')\n",
    "a[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26fd98",
   "metadata": {},
   "source": [
    "Set `allow_pickle=True` for multidimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0cedd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1c369284f48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple arrays\n",
    "b = np.load('TEMP/outputs.npz', allow_pickle=True)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d533273",
   "metadata": {},
   "source": [
    "See the arrays stored in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a0ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0', 'arr_1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc82af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78947368, 0.71428571, 0.8       , 0.69565217, 0.5483871 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['arr_0'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a155354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(  1, 'Male', 19,  15, 39), (  2, 'Male', 21,  15, 81),\n",
       "       (  3, 'Female', 20,  16,  6), (  4, 'Female', 23,  16, 77),\n",
       "       (  5, 'Female', 31,  17, 40), (  6, 'Female', 22,  17, 76),\n",
       "       (  7, 'Female', 35,  18,  6), (  8, 'Female', 23,  18, 94),\n",
       "       (  9, 'Male', 64,  19,  3), ( 10, 'Female', 30,  19, 72),\n",
       "       ( 11, 'Male', 67,  19, 14), ( 12, 'Female', 35,  19, 99),\n",
       "       ( 13, 'Female', 58,  20, 15), ( 14, 'Female', 24,  20, 77),\n",
       "       ( 15, 'Male', 37,  20, 13), ( 16, 'Male', 22,  20, 79),\n",
       "       ( 17, 'Female', 35,  21, 35), ( 18, 'Male', 20,  21, 66),\n",
       "       ( 19, 'Male', 52,  23, 29), ( 20, 'Female', 35,  23, 98),\n",
       "       ( 21, 'Male', 35,  24, 35), ( 22, 'Male', 25,  24, 73),\n",
       "       ( 23, 'Female', 46,  25,  5), ( 24, 'Male', 31,  25, 73),\n",
       "       ( 25, 'Female', 54,  28, 14), ( 26, 'Male', 29,  28, 82),\n",
       "       ( 27, 'Female', 45,  28, 32), ( 28, 'Male', 35,  28, 61),\n",
       "       ( 29, 'Female', 40,  29, 31), ( 30, 'Female', 23,  29, 87),\n",
       "       ( 31, 'Male', 60,  30,  4), ( 32, 'Female', 21,  30, 73),\n",
       "       ( 33, 'Male', 53,  33,  4), ( 34, 'Male', 18,  33, 92),\n",
       "       ( 35, 'Female', 49,  33, 14), ( 36, 'Female', 21,  33, 81),\n",
       "       ( 37, 'Female', 42,  34, 17), ( 38, 'Female', 30,  34, 73),\n",
       "       ( 39, 'Female', 36,  37, 26), ( 40, 'Female', 20,  37, 75),\n",
       "       ( 41, 'Female', 65,  38, 35), ( 42, 'Male', 24,  38, 92),\n",
       "       ( 43, 'Male', 48,  39, 36), ( 44, 'Female', 31,  39, 61),\n",
       "       ( 45, 'Female', 49,  39, 28), ( 46, 'Female', 24,  39, 65),\n",
       "       ( 47, 'Female', 50,  40, 55), ( 48, 'Female', 27,  40, 47),\n",
       "       ( 49, 'Female', 29,  40, 42), ( 50, 'Female', 31,  40, 42),\n",
       "       ( 51, 'Female', 49,  42, 52), ( 52, 'Male', 33,  42, 60),\n",
       "       ( 53, 'Female', 31,  43, 54), ( 54, 'Male', 59,  43, 60),\n",
       "       ( 55, 'Female', 50,  43, 45), ( 56, 'Male', 47,  43, 41),\n",
       "       ( 57, 'Female', 51,  44, 50), ( 58, 'Male', 69,  44, 46),\n",
       "       ( 59, 'Female', 27,  46, 51), ( 60, 'Male', 53,  46, 46),\n",
       "       ( 61, 'Male', 70,  46, 56), ( 62, 'Male', 19,  46, 55),\n",
       "       ( 63, 'Female', 67,  47, 52), ( 64, 'Female', 54,  47, 59),\n",
       "       ( 65, 'Male', 63,  48, 51), ( 66, 'Male', 18,  48, 59),\n",
       "       ( 67, 'Female', 43,  48, 50), ( 68, 'Female', 68,  48, 48),\n",
       "       ( 69, 'Male', 19,  48, 59), ( 70, 'Female', 32,  48, 47),\n",
       "       ( 71, 'Male', 70,  49, 55), ( 72, 'Female', 47,  49, 42),\n",
       "       ( 73, 'Female', 60,  50, 49), ( 74, 'Female', 60,  50, 56),\n",
       "       ( 75, 'Male', 59,  54, 47), ( 76, 'Male', 26,  54, 54),\n",
       "       ( 77, 'Female', 45,  54, 53), ( 78, 'Male', 40,  54, 48),\n",
       "       ( 79, 'Female', 23,  54, 52), ( 80, 'Female', 49,  54, 42),\n",
       "       ( 81, 'Male', 57,  54, 51), ( 82, 'Male', 38,  54, 55),\n",
       "       ( 83, 'Male', 67,  54, 41), ( 84, 'Female', 46,  54, 44),\n",
       "       ( 85, 'Female', 21,  54, 57), ( 86, 'Male', 48,  54, 46),\n",
       "       ( 87, 'Female', 55,  57, 58), ( 88, 'Female', 22,  57, 55),\n",
       "       ( 89, 'Female', 34,  58, 60), ( 90, 'Female', 50,  58, 46),\n",
       "       ( 91, 'Female', 68,  59, 55), ( 92, 'Male', 18,  59, 41),\n",
       "       ( 93, 'Male', 48,  60, 49), ( 94, 'Female', 40,  60, 40),\n",
       "       ( 95, 'Female', 32,  60, 42), ( 96, 'Male', 24,  60, 52),\n",
       "       ( 97, 'Female', 47,  60, 47), ( 98, 'Female', 27,  60, 50),\n",
       "       ( 99, 'Male', 48,  61, 42), (100, 'Male', 20,  61, 49),\n",
       "       (101, 'Female', 23,  62, 41), (102, 'Female', 49,  62, 48),\n",
       "       (103, 'Male', 67,  62, 59), (104, 'Male', 26,  62, 55),\n",
       "       (105, 'Male', 49,  62, 56), (106, 'Female', 21,  62, 42),\n",
       "       (107, 'Female', 66,  63, 50), (108, 'Male', 54,  63, 46),\n",
       "       (109, 'Male', 68,  63, 43), (110, 'Male', 66,  63, 48),\n",
       "       (111, 'Male', 65,  63, 52), (112, 'Female', 19,  63, 54),\n",
       "       (113, 'Female', 38,  64, 42), (114, 'Male', 19,  64, 46),\n",
       "       (115, 'Female', 18,  65, 48), (116, 'Female', 19,  65, 50),\n",
       "       (117, 'Female', 63,  65, 43), (118, 'Female', 49,  65, 59),\n",
       "       (119, 'Female', 51,  67, 43), (120, 'Female', 50,  67, 57),\n",
       "       (121, 'Male', 27,  67, 56), (122, 'Female', 38,  67, 40),\n",
       "       (123, 'Female', 40,  69, 58), (124, 'Male', 39,  69, 91),\n",
       "       (125, 'Female', 23,  70, 29), (126, 'Female', 31,  70, 77),\n",
       "       (127, 'Male', 43,  71, 35), (128, 'Male', 40,  71, 95),\n",
       "       (129, 'Male', 59,  71, 11), (130, 'Male', 38,  71, 75),\n",
       "       (131, 'Male', 47,  71,  9), (132, 'Male', 39,  71, 75),\n",
       "       (133, 'Female', 25,  72, 34), (134, 'Female', 31,  72, 71),\n",
       "       (135, 'Male', 20,  73,  5), (136, 'Female', 29,  73, 88),\n",
       "       (137, 'Female', 44,  73,  7), (138, 'Male', 32,  73, 73),\n",
       "       (139, 'Male', 19,  74, 10), (140, 'Female', 35,  74, 72),\n",
       "       (141, 'Female', 57,  75,  5), (142, 'Male', 32,  75, 93),\n",
       "       (143, 'Female', 28,  76, 40), (144, 'Female', 32,  76, 87),\n",
       "       (145, 'Male', 25,  77, 12), (146, 'Male', 28,  77, 97),\n",
       "       (147, 'Male', 48,  77, 36), (148, 'Female', 32,  77, 74),\n",
       "       (149, 'Female', 34,  78, 22), (150, 'Male', 34,  78, 90),\n",
       "       (151, 'Male', 43,  78, 17), (152, 'Male', 39,  78, 88),\n",
       "       (153, 'Female', 44,  78, 20), (154, 'Female', 38,  78, 76),\n",
       "       (155, 'Female', 47,  78, 16), (156, 'Female', 27,  78, 89),\n",
       "       (157, 'Male', 37,  78,  1), (158, 'Female', 30,  78, 78),\n",
       "       (159, 'Male', 34,  78,  1), (160, 'Female', 30,  78, 73),\n",
       "       (161, 'Female', 56,  79, 35), (162, 'Female', 29,  79, 83),\n",
       "       (163, 'Male', 19,  81,  5), (164, 'Female', 31,  81, 93),\n",
       "       (165, 'Male', 50,  85, 26), (166, 'Female', 36,  85, 75),\n",
       "       (167, 'Male', 42,  86, 20), (168, 'Female', 33,  86, 95),\n",
       "       (169, 'Female', 36,  87, 27), (170, 'Male', 32,  87, 63),\n",
       "       (171, 'Male', 40,  87, 13), (172, 'Male', 28,  87, 75),\n",
       "       (173, 'Male', 36,  87, 10), (174, 'Male', 36,  87, 92),\n",
       "       (175, 'Female', 52,  88, 13), (176, 'Female', 30,  88, 86),\n",
       "       (177, 'Male', 58,  88, 15), (178, 'Male', 27,  88, 69),\n",
       "       (179, 'Male', 59,  93, 14), (180, 'Male', 35,  93, 90),\n",
       "       (181, 'Female', 37,  97, 32), (182, 'Female', 32,  97, 86),\n",
       "       (183, 'Male', 46,  98, 15), (184, 'Female', 29,  98, 88),\n",
       "       (185, 'Female', 41,  99, 39), (186, 'Male', 30,  99, 97),\n",
       "       (187, 'Female', 54, 101, 24), (188, 'Male', 28, 101, 68),\n",
       "       (189, 'Female', 41, 103, 17), (190, 'Female', 36, 103, 85),\n",
       "       (191, 'Female', 34, 103, 23), (192, 'Female', 32, 103, 69),\n",
       "       (193, 'Male', 33, 113,  8), (194, 'Female', 38, 113, 91),\n",
       "       (195, 'Female', 47, 120, 16), (196, 'Female', 35, 120, 79),\n",
       "       (197, 'Female', 45, 126, 28), (198, 'Male', 32, 126, 74),\n",
       "       (199, 'Male', 32, 137, 18), (200, 'Male', 30, 137, 83)],\n",
       "      dtype=[('CustomerID', '<i2'), ('Genre', '<U16'), ('Age', '<i2'), ('Annual_Income', '<i2'), ('Spending_Score', '<i2')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3ccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
